---
title:  "5월 20일 연구 진행 상황" 

categories:
  - Conformal_RAG
tags:
  - [RAG, Conformal_Prediction, Research]

toc: true
toc_sticky: true

date: 2024-05-20
last_modified_at: 2024-05-23
---  

## 1. 데이터셋 생성  
RAG를 pre-trained할 때 쓰인 dataset을 찾지 못했다. 그래서 dev dataset을 나누어 사용해야 할 듯하다.  
dev dataset에는 총 6515개의 data가 있다. 이를 train:validation:test = 2:1:1로 나누어 사용할 예정이다.  

그러면 바로 dev data를 2:1:1로 나누어보자. 완전히 랜덤으로 나누어야 하는데, 이 코드는 아래와 같다.  
[split code](Original_RAG/output/data_split.ipynb)  
split한 코드는 data_folder에 넣었다.  

데이터가 부족하면 huggingface의 data를 모델이 학습할 수 있도록 재가공하여 추가할 예정이다. 데이터는 아래 사이트에서 가져오면 된다.  
[extra data](https://huggingface.co/datasets?sort=downloads&search=RAG)  

그러면 일단 dev data를 e2e evaluation에 사용할 수 있도록 변형해야 한다. READMD.md를 보면, 단순히 각각의 line을 list로 바꾸어주면 해결할 수 있다.  

dst.txt에 list 형식으로 바꾼 dataset을 저장했다.  

```bash
python eval_rag.py \
    --model_name_or_path facebook/rag-sequence-base \
    --model_type rag_sequence \
    --evaluation_set data_folder/test.source \
    --gold_data_path data_folder/test.target \
    --predictions_path output/original_preds.tsv \
    --eval_mode e2e \
    --gold_data_mode qa \
    --n_docs 5 \
    --print_predictions \
    --recalculate
```

이 코드만 잘 돌려주면 된다.  

그냥 pre-trained model로 e2e evaluation을 해보앗는데, 생각보다 오래 걸린다. 대략 50시간 정도 걸리는 듯하다. 데이터셋을 추가해서 finetuning하려던 생각은 매우 무모한 생각이었다..  
지금 이 코드 실행 시간이 비정상적으로 긴데, 아마도 GPU를 사용하지 않기 때문인 듯하다. 이거는 교수님께서 slack을 확인하시는 대로 해결해보자.  

일단, 저 코드가 다 돌아가도, 결국 오류가 나타나는데...
```bash
Traceback (most recent call last):
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 343, in <module>
    main(args)
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 309, in main
    score_fn(args, args.predictions_path, args.gold_data_path)
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 46, in get_scores
    data = pd.read_csv(gold_data_path, sep="\t", header=None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 617, in _read
    return parser.read(nrows)
           ^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 1748, in read
    ) = self._engine.read(  # type: ignore[attr-defined]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
    chunks = self._reader.read_low_memory(nrows)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "parsers.pyx", line 843, in pandas._libs.parsers.TextReader.read_low_memory
  File "parsers.pyx", line 904, in pandas._libs.parsers.TextReader._read_rows
  File "parsers.pyx", line 879, in pandas._libs.parsers.TextReader._tokenize_rows
  File "parsers.pyx", line 890, in pandas._libs.parsers.TextReader._check_tokenize_status
  File "parsers.pyx", line 2058, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 8 fields in line 3, saw 16
```
문제가 되는 곳을 보니, test.target의 형식이 잘못되었다.  
리스트 형식으로 바꿔보았는데, 여전히 문제가 있다.  
```bash
INFO:__main__:Evaluate the following checkpoints: ['facebook/rag-sequence-base']
INFO:__main__:Calculating metrics based on an existing predictions file: output/original_preds.csv
Traceback (most recent call last):
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 2606, in pandas._libs.hashtable.Int64HashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 2630, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 343, in <module>
    main(args)
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 309, in main
    score_fn(args, args.predictions_path, args.gold_data_path)
  File "/home/flash/Conformal_RAG/Original_RAG/eval_rag.py", line 47, in get_scores
    for answer_list in data[1]:
                       ~~~~^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py", line 3893, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 1
```
문제가 되었던 eval_rag.py의 코드가 다음과 같았는데,  
```python
def get_scores(args, preds_path, gold_data_path):
    hypos = [line.strip() for line in open(preds_path, "r").readlines()]
    answers = []

    if args.gold_data_mode == "qa":
        data = pd.read_csv(gold_data_path, sep="\t", header=None)
        for answer_list in data[1]:       # 여기에서 문제 발생!
            ground_truths = ast.literal_eval(answer_list)
            answers.append(ground_truths)
    else:
        references = [line.strip() for line in open(gold_data_path, "r").readlines()]
        answers = [[reference] for reference in references]

    f1 = em = total = 0
    for prediction, ground_truths in zip(hypos, answers):
        total += 1
        em += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)
        f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)

    em = 100.0 * em / total
    f1 = 100.0 * f1 / total

    logger.info(f"F1: {f1:.2f}")
    logger.info(f"EM: {em:.2f}")

```
아마도 리스트에 정답이 1개밖에 없는 경우 index error가 발생할 것이라 생각해 data[1]을 data[0]으로 수정했더니 결과가 나왔다.  

결과는 다음과 같았다.  

```bash
INFO:__main__:Evaluate the following checkpoints: ['facebook/rag-sequence-base']
INFO:__main__:Calculating metrics based on an existing predictions file: output/original_preds.csv
INFO:__main__:F1: 1.95
INFO:__main__:EM: 0.00
```

참고로 사용한 original_preds.csv는 pre-trained된 모델을 사용한 결과로, 아래 코드를 사용했다.  
```bash
python eval_rag.py \
    --model_name_or_path facebook/rag-sequence-base \
    --model_type rag_sequence \
    --evaluation_set data_folder/test.source \
    --gold_data_path data_folder/test.target \
    --predictions_path output/original_preds.csv \
    --eval_mode e2e \
    --gold_data_mode qa \
    --n_docs 1 \
    --print_predictions \
```

문제는 eval_rag.py가 정상적으로 돌아간다 하더라도, 결국 finetuning이 되지 않으면 아무런 쓸모가 없다..  

아래 코드는 finetuning 코드다.  
```bash
python finetune_rag.py \
    --data_dir data_folder \
    --output_dir result_folder \
    --model_name_or_path facebook/rag-sequence-base \
    --model_type rag_sequence \
    --fp16 \
    --gpus 1 \
    --distributed_retriever pytorch
```
이 코드를 돌려보았는데, 사용 가능한 GPU가 없다고 한다.  

일단 GPU가 없는 김에 진행 방향을 정리하면,
1. train set으로 k=5로 finetuning하고, test set으로 evaluation  
2. validation set으로 k를 정하고, 해당 k를 사용해 train set으로 fine tuning한 뒤에 test set으로 evaluation  

GPU가 없는 이유가 Nvidia driver 버전 이슈라고 해서 찾아봤더니, 그냥 cuda 버전만 낮추면 되는 문제였다.  

다시 코드를 돌려보니..
```bash
Traceback (most recent call last):
  File "/home/flash/Conformal_RAG/Original_RAG/finetune_rag.py", line 652, in <module>
    main(args)
  File "/home/flash/Conformal_RAG/Original_RAG/finetune_rag.py", line 589, in main
    model: GenerativeQAModule = GenerativeQAModule(args)
                                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/Conformal_RAG/Original_RAG/finetune_rag.py", line 155, in __init__
    super().__init__(hparams, config=config, tokenizer=tokenizer, model=model)
  File "/home/flash/Conformal_RAG/Original_RAG/lightning_base.py", line 75, in __init__
    super().__init__()
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/lightning.py", line 116, in __init__
    self._register_sharded_tensor_state_dict_hooks_if_available()
  File "/home/flash/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/lightning.py", line 2046, in _register_sharded_tensor_state_dict_hooks_if_available
    from torch.distributed._sharded_tensor import pre_load_state_dict_hook, state_dict_hook
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_sharded_tensor/__init__.py", line 7, in <module>
    from torch.distributed._shard.sharded_tensor import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/__init__.py", line 1, in <module>
    from .api import (
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/api.py", line 6, in <module>
    from torch.distributed._shard.sharded_tensor import (
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/sharded_tensor/__init__.py", line 8, in <module>
    import torch.distributed._shard.sharding_spec as shard_spec
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/sharding_spec/__init__.py", line 1, in <module>
    from .api import (
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/sharding_spec/api.py", line 16, in <module>
    import torch.distributed._shard.sharded_tensor.metadata as sharded_tensor_meta
  File "/home/flash/anaconda3/lib/python3.11/site-packages/torch/distributed/_shard/sharded_tensor/metadata.py", line 70, in <module>
    @dataclass
     ^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/dataclasses.py", line 1230, in dataclass
    return wrap(cls)
           ^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/dataclasses.py", line 1220, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/dataclasses.py", line 958, in _process_class
    cls_fields.append(_get_field(cls, name, type, kw_only))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/flash/anaconda3/lib/python3.11/dataclasses.py", line 815, in _get_field
    raise ValueError(f'mutable default {type(f.default)} for field '
ValueError: mutable default <class 'torch.distributed._shard.sharded_tensor.metadata.TensorProperties'> for field tensor_properties is not allowed: use default_factory
```
결국 또 error가 뜬다. 지금 뜨는 error들이 전부 호환과 관련된 문제라서 conda 환경을 새로 파기로 했다. python 3.10.0으로 새로운 가상환경을 만들었다.  
만든 뒤 다음과 같이 터미널에 입력한다.  
```bash
pip install faiss-cpu
pip install datasets
pip install psutil
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip install ray
pip install pytorch-lightning==1.6.0
pip install transformers
pip install GitPython
```
requirement에는 torch의 버전이 상관 없다고 나오지만, 현재 nvidia driver와 호환되는 cuda를 사용하기 위해 torch의 버전을 제한했다.  
그 뒤에 코드를 돌렸는데 다음과 같이 출력되고 종료된다.  
```bash
INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpvfvdhx8s
INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpvfvdhx8s/_remote_module_non_scriptable.py
/home/flash/Conformal_RAG/.conda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
/home/flash/Conformal_RAG/.conda/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
  rank_zero_deprecation(
Global seed set to 42
/home/flash/Conformal_RAG/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:439: UserWarning: The flag `devices=auto` will be ignored, instead the device specific number 2 will be used
  rank_zero_warn(
Using 16bit native Automatic Mixed Precision (AMP)
/home/flash/Conformal_RAG/.conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
  rank_zero_warn(
/home/flash/Conformal_RAG/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
```


## 2. Conformal Prediction 식 표현 및 기존 CP와 호환 가능 여부 확인  

$$C(x) = \{y | rank(f(x, y)) <= k \}$$  
기존에 작성했던 식이다. 이 식에서 rank 함수를 엄밀하게 정의할 필요가 있다.  

$$ rank(f(x, y)) = \sum_{y' \in Y} \mathbf{1}(f(x, y') \geq f(x, y)) $$  
$$ C(x) = \{ y \mid \text{rank}(f(x, y)) \leq k \} $$  

이때, k를 산정하는 방식은 true dataset에 대해, top-K 내에 정답 데이터가 있을 확률이 90% 이상이 되도록 하는 최소의 k이므로,

$$ \argmin_{k} \ ( \hat{P} (y_{true} \in C(x)) = \frac{1}{|D|} \sum_{(x, y_{true}) \in D} \mathbf{1}(\text{rank}(f(x, y_{true})) \leq k) \geq 0.90) $$  
위와 같이 표현할 수 있을 것이다.  

일반화를 해보면,  
$$ \argmin_{k} \ ( \hat{P} (y_{true} \in C(x)) = \frac{1}{|D|} \sum_{(x, y_{true}) \in D} \mathbf{1}(\text{rank}(f(x, y_{true})) \leq k) \geq 1 - \alpha) $$  
로 나타낼 수 있다.  

그러면, 이러한 k를 구하는 알고리즘을 pseudo code로 표현해보자.  

### Optimal k 찾기 알고리즘  
```
Algorithm FindOptimalK(D, alpha = 0.10):
    Input:
        D: A dataset of (x, y_true) pairs
        alpha: The acceptable error rate (default 0.10, corresponding to 90% confidence)
    Output:
        k: The optimal number of top-ranked results to include

    Initialize:
        k = 1
    
    While True:
        correct_count = 0

        For each (x, y_true) in D:
            Compute rank(f(x, y_true))
            If rank(f(x, y_true)) <= k:
                correct_count += 1
        
        empirical_prob = correct_count / len(D)
        
        If empirical_prob >= 1 - alpha:
            Return k
        Else:
            k += 1
```

## 3. Retrieval Evaluation으로 k를 찾는 코드 만들기  
```python
def get_K(args, preds_path, gold_data_path):
    k = 1
    references = [line.strip() for line in open(gold_data_path, "r").readlines()]
    hypos = [line.strip() for line in open(preds_path, "r").readlines()]
        
    while k < args.n_docs:
        em = total = 0
        for hypo, reference in zip(hypos, references):
            hypo_provenance = set(hypo.split("\t")[:k])
            ref_provenance = set(reference.split("\t"))
            
            total += 1
            #em += len(hypo_provenance & ref_provenance) / k
            em += 1 if len(hypo_provenance & ref_provenance) else 0
    
        em = em / total
        
        if em >= 1 - args.error_rate:
            logger.info(f"minimum k is {k}")
            logger.info(f"Precision@{k}: {100*em: .2f}")
            return
        k += 1
    logger.info("There's no K with given error rate")
```
```python
def get_args():
  ...
  parser.add_argument(
        "--find_K",
        action="store_true",
        help="find k with given error rate."
    )
    parser.add_argument(
        "--error_rate",
        default=0.1,
        type=float,
        help="find k with given error rate."
    )
```
```python
def main(args):
    model_kwargs = {}
    if args.model_type is None:
        args.model_type = infer_model_type(args.model_name_or_path)
        assert args.model_type is not None
    if args.model_type.startswith("rag"):
        model_class = RagTokenForGeneration if args.model_type == "rag_token" else RagSequenceForGeneration
        model_kwargs["n_docs"] = args.n_docs
        if args.index_name is not None:
            model_kwargs["index_name"] = args.index_name
        if args.index_path is not None:
            model_kwargs["index_path"] = args.index_path
    else:
        model_class = BartForConditionalGeneration

    checkpoints = (
        [f.path for f in os.scandir(args.model_name_or_path) if f.is_dir()]
        if args.eval_all_checkpoints
        else [args.model_name_or_path]
    )

    logger.info("Evaluate the following checkpoints: %s", checkpoints)

    score_fn = get_scores if args.eval_mode == "e2e" else get_K if args.find_K else get_precision_at_k2
    evaluate_batch_fn = evaluate_batch_e2e if args.eval_mode == "e2e" else evaluate_batch_retrieval

    for checkpoint in checkpoints:
        if os.path.exists(args.predictions_path) and (not args.recalculate):
            logger.info("Calculating metrics based on an existing predictions file: {}".format(args.predictions_path))
            score_fn(args, args.predictions_path, args.gold_data_path)
            continue

        logger.info("***** Running evaluation for {} *****".format(checkpoint))
        logger.info("  Batch size = %d", args.eval_batch_size)
        logger.info("  Predictions will be stored under {}".format(args.predictions_path))

        if args.model_type.startswith("rag"):
            retriever = RagRetriever.from_pretrained(checkpoint, **model_kwargs)
            model = model_class.from_pretrained(checkpoint, retriever=retriever, **model_kwargs)
            model.retriever.init_retrieval()
        else:
            model = model_class.from_pretrained(checkpoint, **model_kwargs)
        model.to(args.device)

        with open(args.evaluation_set, "r") as eval_file, open(args.predictions_path, "w") as preds_file:
            questions = []
            for line in tqdm(eval_file):
                questions.append(line.strip())
                if len(questions) == args.eval_batch_size:
                    answers = evaluate_batch_fn(args, model, questions)
                    preds_file.write("\n".join(answers) + "\n")
                    preds_file.flush()
                    questions = []
            if len(questions) > 0:
                answers = evaluate_batch_fn(args, model, questions)
                preds_file.write("\n".join(answers))
                preds_file.flush()

            score_fn(args, args.predictions_path, args.gold_data_path)
```
위와 같이 eval_rag.oy를 수정하여, argument로 find_K와 error_rate를 넘기면 그에 맞는 k를 찾을 수 있도록 변경했다.  

아래와 같이 터미널에 입력하면 된다.  
```bash
python eval_rag.py \
--model_name_or_path facebook/rag-sequence-base \
--model_type rag_sequence \
--evaluation_set data_folder/test_question.txt \
--gold_data_path data_folder/test_answer.txt  \
--predictions_path output/temp_preds.csv \
--eval_mode retrieval \
--n_docs 1000
--find_K
```
이렇게 헸을 때, 나온 K의 값은 123이었다.  

전체 데이터 셋으로 돌린 결과는 50으로, 이전에 구한 K와 일치했다.  