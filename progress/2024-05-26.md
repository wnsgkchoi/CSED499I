---
title:  "5월 26일 연구 진행 상황" 

categories:
  - Conformal_RAG
tags:
  - [RAG, Conformal_Prediction, Research]

toc: true
toc_sticky: true

date: 2024-05-26
last_modified_at: 2024-05-26
---  

> 2024-05-24.md가 error 출력때문에 너무 길어지고 복잡해서 새로 문서를 만들었다. 또한 사용 코드를 rag에서 rag-end2end-retriever로 변경했다. 바꾼다고 해결이 될지 모르겠지만, 어차피 rag를 사용한다고 해도, 이를 고칠 자신이 없기 때문에 괜찮을 듯하다.  


## 0. 몰라  
몰라  

## 1. get_K  
이전과 똑같이 코드를 수정했다. 과연 code가 똑같이 동작할지 모르겠지만, 일단 해보자.  

### 1. data 만들기  
먼저 evaluation할 data가 필요하다. 이는 Original_RAG에서 생성했던 데이터를 그대로 가져왔다.  

### 2. Retrievel eval_RAG 해보기  
이 함수가 예전과 똑같이 동작하는지 확인할 필요가 있다.  

```bash
python eval_rag.py \
--model_name_or_path facebook/rag-sequence-base \
--model_type rag_sequence \
--evaluation_set data/val_question.txt \
--gold_data_path data/val_answer.txt  \
--predictions_path output/get_k_preds.csv \
--eval_mode retrieval \
--n_docs 200 \
--get_K
```
minimum k = 34가 나왔다.  

### 3. finetuning 해보기  
```bash
RAY_memory_monitor_refresh_ms=0 ray start --head

python use_own_knowledge_dataset.py  \
    --csv_path finetune_data/SQUAD-KB/squad-kb.csv \
    --output_dir finetune_data/SQUAD-KB

python finetune_rag.py \
    --data_dir  finetune_data/squad-training-data \
    --output_dir output/model \
    --model_name_or_path facebook/rag-sequence-base \
    --model_type rag_sequence \
    --fp16 \
    --gpus 2  \
    --profile \
    --do_train \
    --end2end \
    --do_predict \
    --n_val -1  \
    --train_batch_size 4 \
    --eval_batch_size 1 \
    --max_source_length 128 \
    --max_target_length 25 \
    --val_max_target_length 25 \
    --test_max_target_length 25 \
    --label_smoothing 0.1 \
    --dropout 0.1 \
    --attention_dropout 0.1 \
    --weight_decay 0.001 \
    --adam_epsilon 1e-08 \
    --max_grad_norm 0.1 \
    --lr_scheduler polynomial \
    --learning_rate 2e-03 \
    --num_train_epochs 10 \
    --warmup_steps 50 \
    --gradient_accumulation_steps 1 \
    --distributed_retriever ray \
    --num_retrieval_workers 4  \
    --passages_path finetune_data/SQUAD-KB/my_knowledge_dataset \
    --index_path  finetune_data/SQUAD-KB/my_knowledge_dataset_hnsw_index.faiss \
    --index_name custom \
    --context_encoder_name facebook/dpr-ctx_encoder-multiset-base \
    --index_gpus 1 \
    --gpu_order [5,6,7,8,9,0,1,2,3,4] \
    --indexing_freq 5
```

```bash
python eval_rag.py \
    --model_name_or_path output/model/checkpoint33 \
    --model_type rag_sequence \
    --evaluation_set data/test_question.txt \
    --gold_data_path data/test_answer.txt \
    --predictions_path output/standard_preds.tsv \
    --eval_mode e2e \
    --gold_data_mode qa \
    --n_docs 50 \
    --k 1 \
    --print_predictions \
    --recalculate
```

```bash
python eval_rag.py \
    --model_name_or_path facebook/rag-token-base \
    --model_type rag_token \
    --evaluation_set data/test_question.txt \
    --gold_data_path data/test_gold_data.txt \
    --predictions_path output/standard_preds.csv \
    --eval_mode e2e \
    --gold_data_mode qa \
    --n_docs 10 \
    --k 1 \
    --print_predictions \
    --recalculate
```

```bash
python eval_rag.py \
    --model_name_or_path output/model/checkpoint33 \
    --model_type rag_sequence \
    --evaluation_set data/test_question.txt \
    --gold_data_path data/test_answer.txt \
    --predictions_path output/standard_retrieval_preds.tsv  \
    --eval_mode retrieval \
    --k 1
```

```bash
python eval_rag.py \
  --model_name_or_path facebook/rag-sequence-base \
  --model_type rag_sequence \
  --evaluation_set data/val_question.txt \
  --gold_data_path data/val_answer.txt  \
  --predictions_path output/get_k_preds.csv \
  --eval_mode retrieval \
  --n_docs 1000 \
  --get_K \
  --recalculate
```

python eval_rag.py \
